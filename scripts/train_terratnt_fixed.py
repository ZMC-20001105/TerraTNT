#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è®­ç»ƒ TerraTNT æ¨¡å‹ - ä¿®å¤ç‰ˆæœ¬
å…³é”®ä¿®å¤ï¼š
1. åæ ‡å½’ä¸€åŒ–ï¼ˆç›¸å¯¹äºå½“å‰ç‚¹ï¼‰
2. æ­£ç¡®çš„ goal å®šä¹‰ï¼ˆfuture[-1] è€Œä¸æ˜¯ path[-1]ï¼‰
3. è®­ç»ƒè¿‡ç¨‹å¥åº·æ£€æŸ¥ï¼ˆå®šæœŸéªŒè¯ ADE/FDEï¼‰
"""
import sys
sys.path.insert(0, '/home/zmc/æ–‡æ¡£/programwork')

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from pathlib import Path
import pickle
import numpy as np
import json
from datetime import datetime
from tqdm import tqdm
import warnings

class FASTrajectoryDatasetFixed(Dataset):
    """FAS é˜¶æ®µç‰¹å®šçš„è½¨è¿¹æ•°æ®é›† - ä¿®å¤ç‰ˆ"""
    
    def __init__(self, traj_dir, fas_split_file, phase='fas1', 
                 history_len=10, future_len=60, num_candidates=6):
        self.traj_dir = Path(traj_dir)
        self.phase = phase
        self.history_len = history_len
        self.future_len = future_len
        self.num_candidates = num_candidates
        
        # åŠ è½½ FAS åˆ’åˆ†
        with open(fas_split_file, 'r') as f:
            splits = json.load(f)
        
        self.file_list = splits[phase]['files']
        print(f"{phase.upper()}: åŠ è½½ {len(self.file_list)} ä¸ªè½¨è¿¹æ–‡ä»¶")
        
        # é¢„å¤„ç†æ ·æœ¬
        self.samples = []
        self._prepare_samples()
    
    def _prepare_samples(self):
        print(f"å‡†å¤‡ {self.phase.upper()} æ ·æœ¬...")
        
        for file_name in tqdm(self.file_list, desc=f"å¤„ç†{self.phase}"):
            traj_file = self.traj_dir / file_name
            
            try:
                with open(traj_file, 'rb') as f:
                    data = pickle.load(f)
                
                path = np.array([(p[0], p[1]) for p in data.get('path', data.get('path_utm', []))])
                
                if len(path) < self.history_len + self.future_len:
                    continue
                
                # æ»‘åŠ¨çª—å£é‡‡æ ·
                for start_idx in range(0, len(path) - self.history_len - self.future_len, 30):
                    history = path[start_idx:start_idx + self.history_len]
                    future = path[start_idx + self.history_len:start_idx + self.history_len + self.future_len]
                    
                    # å…³é”®ä¿®å¤ï¼šgoal æ˜¯å½“å‰çª—å£çš„ç»ˆç‚¹ï¼Œè€Œä¸æ˜¯æ•´æ¡è½¨è¿¹çš„ç»ˆç‚¹
                    goal = future[-1]  # 60åˆ†é’Ÿåçš„ä½ç½®
                    current_pos = history[-1]  # å½“å‰ä½ç½®
                    
                    # å½’ä¸€åŒ–ï¼šç›¸å¯¹äºå½“å‰ä½ç½®
                    history_rel = history - current_pos
                    future_rel = future - current_pos
                    goal_rel = goal - current_pos
                    
                    self.samples.append({
                        'history': history_rel,
                        'future': future_rel,
                        'goal': goal_rel,
                        'current_pos': current_pos,  # ä¿å­˜ç”¨äºåå½’ä¸€åŒ–
                        'traj_file': str(traj_file)
                    })
            
            except Exception as e:
                continue
        
        print(f"{self.phase.upper()} æ ·æœ¬æ•°: {len(self.samples)}")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        
        history = torch.FloatTensor(sample['history'])
        future = torch.FloatTensor(sample['future'])
        goal = torch.FloatTensor(sample['goal'])
        current_pos = torch.FloatTensor(sample['current_pos'])
        
        # ç”Ÿæˆå€™é€‰ç»ˆç‚¹ï¼ˆç›¸å¯¹åæ ‡ï¼‰
        candidates = self._generate_candidates(sample['goal'], sample['traj_file'])
        
        return {
            'history': history,
            'future': future,
            'goal': goal,
            'candidates': candidates,
            'current_pos': current_pos
        }
    
    def _generate_candidates(self, true_goal_rel, traj_file):
        """
        ç”Ÿæˆå€™é€‰ç»ˆç‚¹é›†åˆï¼ˆç›¸å¯¹åæ ‡ï¼‰
        
        FAS1/FAS2: å€™é€‰é›†åŒ…å«çœŸå®ç»ˆç‚¹ï¼ˆå®Œå¤‡ï¼‰
        FAS3: å€™é€‰é›†ä¸åŒ…å«çœŸå®ç»ˆç‚¹ï¼ˆä¸å®Œå¤‡ï¼‰
        """
        candidates = []
        
        if self.phase in ['fas1', 'fas2']:
            # å®Œå¤‡å€™é€‰é›†ï¼šåŒ…å«çœŸå®ç»ˆç‚¹
            candidates.append(true_goal_rel)
            
            # æ·»åŠ è´Ÿæ ·æœ¬ï¼ˆç›¸å¯¹åæ ‡ç©ºé—´çš„éšæœºåç§»ï¼‰
            for _ in range(self.num_candidates - 1):
                # åœ¨ç›¸å¯¹åæ ‡ç©ºé—´ï¼Œåç§»èŒƒå›´åº”è¯¥æ˜¯å‡ åƒç±³çº§åˆ«
                offset = np.random.randn(2) * 3000  # 3km æ ‡å‡†å·®
                neg_candidate = true_goal_rel + offset
                candidates.append(neg_candidate)
        
        else:  # fas3
            # ä¸å®Œå¤‡å€™é€‰é›†ï¼šä¸åŒ…å«çœŸå®ç»ˆç‚¹
            # ç”Ÿæˆå›´ç»•çœŸå€¼ä½†ä¸åŒ…å«çœŸå€¼çš„å€™é€‰ç‚¹
            for _ in range(self.num_candidates):
                # ç¡®ä¿å€™é€‰ç‚¹è·ç¦»çœŸå€¼è‡³å°‘ 1km
                offset = np.random.randn(2) * 3000 + np.random.choice([-1, 1], 2) * 1000
                neg_candidate = true_goal_rel + offset
                candidates.append(neg_candidate)
        
        return torch.FloatTensor(np.array(candidates))


def compute_metrics(pred, target):
    """
    è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆåœ¨ç›¸å¯¹åæ ‡ç©ºé—´ï¼‰
    
    Args:
        pred: (batch, future_len, 2) é¢„æµ‹è½¨è¿¹ï¼ˆç›¸å¯¹åæ ‡ï¼‰
        target: (batch, future_len, 2) çœŸå®è½¨è¿¹ï¼ˆç›¸å¯¹åæ ‡ï¼‰
    
    Returns:
        ade: å¹³å‡ä½ç§»è¯¯å·®ï¼ˆç±³ï¼‰
        fde: æœ€ç»ˆä½ç§»è¯¯å·®ï¼ˆç±³ï¼‰
    """
    # ADE: æ‰€æœ‰æ—¶é—´æ­¥çš„å¹³å‡æ¬§æ°è·ç¦»
    displacement = torch.norm(pred - target, dim=-1)  # (batch, future_len)
    ade = torch.mean(displacement).item()
    
    # FDE: æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„æ¬§æ°è·ç¦»
    fde = torch.mean(displacement[:, -1]).item()
    
    return ade, fde


def health_check(model, val_loader, device, epoch, phase):
    """
    è®­ç»ƒå¥åº·æ£€æŸ¥ï¼šåœ¨å›ºå®šéªŒè¯é›†ä¸Šæµ‹è¯•
    
    å¦‚æœæŒ‡æ ‡å¼‚å¸¸ï¼Œè¿”å› False å¹¶å»ºè®®ä¸­æ­¢è®­ç»ƒ
    """
    model.eval()
    
    # åªç”¨å‰å‡ ä¸ªbatchåšå¿«é€Ÿæ£€æŸ¥
    check_batches = min(10, len(val_loader))
    total_ade = 0
    total_fde = 0
    pred_min, pred_max = float('inf'), float('-inf')
    
    with torch.no_grad():
        for i, batch in enumerate(val_loader):
            if i >= check_batches:
                break
            
            history = batch['history'].to(device)
            future = batch['future'].to(device)
            candidates = batch['candidates'].to(device)
            
            # å½“å‰ä½ç½®åœ¨ç›¸å¯¹åæ ‡ç³»ä¸­æ˜¯ (0, 0)
            current_pos = torch.zeros(history.size(0), 2).to(device)
            
            # ç¯å¢ƒåœ°å›¾ï¼ˆæš‚æ—¶ç”¨é›¶ï¼Œåç»­å¯ä»¥åŠ è½½çœŸå®åœ°å›¾ï¼‰
            env_map = torch.zeros(history.size(0), 18, 128, 128).to(device)
            
            try:
                pred, _ = model(env_map, history, candidates, current_pos)
                if isinstance(pred, tuple):
                    pred = pred[0]
                
                # è®¡ç®—æŒ‡æ ‡
                ade, fde = compute_metrics(pred, future)
                total_ade += ade
                total_fde += fde
                
                # è®°å½•é¢„æµ‹å€¼èŒƒå›´
                pred_min = min(pred_min, pred.min().item())
                pred_max = max(pred_max, pred.max().item())
            
            except Exception as e:
                print(f"    âš ï¸ å¥åº·æ£€æŸ¥æ‰¹æ¬¡å¤±è´¥: {e}")
                continue
    
    avg_ade = total_ade / check_batches
    avg_fde = total_fde / check_batches
    
    print(f"\n  ğŸ“Š å¥åº·æ£€æŸ¥ (Epoch {epoch+1}):")
    print(f"    - ADE: {avg_ade:.2f} m")
    print(f"    - FDE: {avg_fde:.2f} m")
    print(f"    - é¢„æµ‹å€¼èŒƒå›´: [{pred_min:.2f}, {pred_max:.2f}] m")
    
    # å¼‚å¸¸æ£€æµ‹
    is_healthy = True
    warnings_list = []
    
    if avg_ade > 20000:  # 20km
        warnings_list.append(f"ADE è¿‡é«˜ ({avg_ade/1000:.1f} km)")
        is_healthy = False
    
    if np.isnan(avg_ade) or np.isnan(avg_fde):
        warnings_list.append("å‡ºç° NaN")
        is_healthy = False
    
    if abs(pred_min) > 100000 or abs(pred_max) > 100000:  # 100km
        warnings_list.append(f"é¢„æµ‹å€¼èŒƒå›´å¼‚å¸¸ ({pred_min/1000:.1f} ~ {pred_max/1000:.1f} km)")
        is_healthy = False
    
    if warnings_list:
        print(f"    âš ï¸ è­¦å‘Š: {', '.join(warnings_list)}")
        if epoch < 5 and not is_healthy:
            print(f"    âŒ å»ºè®®ä¸­æ­¢è®­ç»ƒï¼šå‰æœŸæŒ‡æ ‡å¼‚å¸¸")
            return False, avg_ade, avg_fde
    else:
        print(f"    âœ… æŒ‡æ ‡æ­£å¸¸")
    
    return True, avg_ade, avg_fde


def train_terratnt_phase(phase, config):
    """è®­ç»ƒ TerraTNT æ¨¡å‹çš„ä¸€ä¸ªé˜¶æ®µ"""
    
    print(f"\n{'='*60}")
    print(f"å¼€å§‹è®­ç»ƒ TerraTNT - {phase.upper()} (ä¿®å¤ç‰ˆ)")
    print('='*60)
    
    # å‡†å¤‡æ•°æ®é›†
    dataset = FASTrajectoryDatasetFixed(
        traj_dir=config['traj_dir'],
        fas_split_file=config['fas_split_file'],
        phase=phase,
        history_len=config['history_len'],
        future_len=config['future_len'],
        num_candidates=config['num_candidates']
    )
    
    if len(dataset) == 0:
        print(f"é”™è¯¯ï¼š{phase} æ²¡æœ‰æœ‰æ•ˆæ ·æœ¬")
        return None
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    val_size = int(len(dataset) * 0.2)
    train_size = len(dataset) - val_size
    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])
    
    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], 
                             shuffle=True, num_workers=10, pin_memory=True)  
    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], 
                           shuffle=False, num_workers=10, pin_memory=True)
    
    # åˆ›å»ºæ¨¡å‹
    from models.terratnt import TerraTNT
    
    model_config = {
        'history_len': config['history_len'],
        'future_len': config['future_len'],
        'hidden_dim': 256,
        'num_goals': config['num_candidates'],
        'map_size': 128,
        'in_channels': 18,
        'env_channels': 18,
        'output_length': config['future_len']
    }
    
    model = TerraTNT(model_config)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    
    # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])
    criterion = nn.MSELoss()
    
    # è®­ç»ƒå¾ªç¯
    best_val_loss = float('inf')
    best_val_ade = float('inf')
    patience_counter = 0
    
    save_dir = Path(config['save_dir']) / f'terratnt_{phase}_fixed' / datetime.now().strftime('%Y%m%d_%H%M%S')
    save_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜é…ç½®
    with open(save_dir / 'config.json', 'w') as f:
        json.dump({**config, **model_config, 'phase': phase}, f, indent=2)
    
    print(f"è®­ç»ƒæ ·æœ¬: {len(train_dataset)}")
    print(f"éªŒè¯æ ·æœ¬: {len(val_dataset)}")
    print(f"ä¿å­˜ç›®å½•: {save_dir}")
    print(f"åæ ‡ç³»ç»Ÿ: ç›¸å¯¹åæ ‡ï¼ˆå½’ä¸€åŒ–åˆ°å½“å‰ä½ç½®ï¼‰")
    
    # è®°å½•è®­ç»ƒå†å²
    history = {
        'train_loss': [],
        'train_ade': [],
        'val_loss': [],
        'val_ade': [],
        'val_fde': []
    }
    
    for epoch in range(config['num_epochs']):
        # è®­ç»ƒ
        model.train()
        train_loss = 0
        train_ade = 0
        
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{config['num_epochs']}")
        for batch in pbar:
            history_batch = batch['history'].to(device)
            future_batch = batch['future'].to(device)
            candidates = batch['candidates'].to(device)
            
            optimizer.zero_grad()
            
            # å½“å‰ä½ç½®åœ¨ç›¸å¯¹åæ ‡ç³»ä¸­æ˜¯åŸç‚¹
            current_pos = torch.zeros(history_batch.size(0), 2).to(device)
            
            # ç¯å¢ƒåœ°å›¾ï¼ˆæš‚æ—¶ç”¨é›¶ï¼‰
            env_map = torch.zeros(history_batch.size(0), 18, 128, 128).to(device)
            
            try:
                pred, goal_probs = model(env_map, history_batch, candidates, current_pos, 
                                        teacher_forcing_ratio=0.5, ground_truth=future_batch)
                if isinstance(pred, tuple):
                    pred = pred[0]
                
                loss = criterion(pred, future_batch)
                loss.backward()
                optimizer.step()
                
                train_loss += loss.item()
                ade, _ = compute_metrics(pred, future_batch)
                train_ade += ade
                
                pbar.set_postfix({'loss': f'{loss.item():.4f}', 'ade': f'{ade:.2f}m'})
            
            except Exception as e:
                print(f"è®­ç»ƒæ‰¹æ¬¡å¤±è´¥: {e}")
                continue
        
        avg_train_loss = train_loss / len(train_loader)
        avg_train_ade = train_ade / len(train_loader)
        
        # éªŒè¯
        model.eval()
        val_loss = 0
        val_ade = 0
        val_fde = 0
        
        with torch.no_grad():
            for batch in val_loader:
                history_batch = batch['history'].to(device)
                future_batch = batch['future'].to(device)
                candidates = batch['candidates'].to(device)
                
                current_pos = torch.zeros(history_batch.size(0), 2).to(device)
                env_map = torch.zeros(history_batch.size(0), 18, 128, 128).to(device)
                
                try:
                    pred, _ = model(env_map, history_batch, candidates, current_pos)
                    if isinstance(pred, tuple):
                        pred = pred[0]
                    
                    loss = criterion(pred, future_batch)
                    val_loss += loss.item()
                    
                    ade, fde = compute_metrics(pred, future_batch)
                    val_ade += ade
                    val_fde += fde
                
                except:
                    continue
        
        avg_val_loss = val_loss / len(val_loader) if len(val_loader) > 0 else float('inf')
        avg_val_ade = val_ade / len(val_loader) if len(val_loader) > 0 else float('inf')
        avg_val_fde = val_fde / len(val_loader) if len(val_loader) > 0 else float('inf')
        
        # è®°å½•å†å²
        history['train_loss'].append(avg_train_loss)
        history['train_ade'].append(avg_train_ade)
        history['val_loss'].append(avg_val_loss)
        history['val_ade'].append(avg_val_ade)
        history['val_fde'].append(avg_val_fde)
        
        print(f"\nEpoch {epoch+1}/{config['num_epochs']}")
        print(f"  è®­ç»ƒ - Loss: {avg_train_loss:.4f}, ADE: {avg_train_ade:.2f}m")
        print(f"  éªŒè¯ - Loss: {avg_val_loss:.4f}, ADE: {avg_val_ade:.2f}m, FDE: {avg_val_fde:.2f}m")
        
        # å¥åº·æ£€æŸ¥
        is_healthy, check_ade, check_fde = health_check(model, val_loader, device, epoch, phase)
        
        if not is_healthy and epoch < 5:
            print(f"\nâŒ è®­ç»ƒå¼‚å¸¸ä¸­æ­¢ï¼šå‰ {epoch+1} ä¸ª epoch æŒ‡æ ‡ä¸æ­£å¸¸")
            print(f"   å»ºè®®æ£€æŸ¥ï¼šæ•°æ®é¢„å¤„ç†ã€æ¨¡å‹æ¶æ„ã€å­¦ä¹ ç‡ç­‰")
            break
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if avg_val_ade < best_val_ade:
            best_val_ade = avg_val_ade
            best_val_loss = avg_val_loss
            patience_counter = 0
            
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': avg_val_loss,
                'val_ade': avg_val_ade,
                'val_fde': avg_val_fde,
                'config': model_config,
                'history': history
            }, save_dir / 'best_model.pth')
            
            print(f"  âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (val_ade={avg_val_ade:.2f}m, val_fde={avg_val_fde:.2f}m)")
        else:
            patience_counter += 1
            if patience_counter >= config['patience']:
                print(f"æ—©åœï¼šéªŒè¯ ADE {config['patience']} è½®æœªæ”¹å–„")
                break
    
    # ä¿å­˜è®­ç»ƒå†å²
    with open(save_dir / 'training_history.json', 'w') as f:
        json.dump(history, f, indent=2)
    
    print(f"\nâœ“ {phase.upper()} è®­ç»ƒå®Œæˆ")
    print(f"  æœ€ä½³éªŒè¯ ADE: {best_val_ade:.2f}m")
    print(f"  æœ€ä½³éªŒè¯ FDE: {history['val_fde'][history['val_ade'].index(best_val_ade)]:.2f}m")
    
    return {
        'phase': phase,
        'best_val_loss': best_val_loss,
        'best_val_ade': best_val_ade,
        'save_dir': str(save_dir),
        'history': history
    }


def main():
    # é…ç½®
    config = {
        'traj_dir': '/home/zmc/æ–‡æ¡£/programwork/data/processed/synthetic_trajectories/bohemian_forest',
        'fas_split_file': '/home/zmc/æ–‡æ¡£/programwork/data/processed/fas_splits/bohemian_forest/fas_splits.json',
        'save_dir': '/home/zmc/æ–‡æ¡£/programwork/runs',
        'batch_size': 32,
        'learning_rate': 0.001,
        'num_epochs': 30,
        'patience': 5,
        'history_len': 10,
        'future_len': 60,
        'num_candidates': 6
    }
    
    print("="*60)
    print("TerraTNT ä¸‰é˜¶æ®µè®­ç»ƒ - ä¿®å¤ç‰ˆ")
    print("="*60)
    print("å…³é”®æ”¹è¿›:")
    print("  1. âœ… åæ ‡å½’ä¸€åŒ–ï¼ˆç›¸å¯¹äºå½“å‰ä½ç½®ï¼‰")
    print("  2. âœ… æ­£ç¡®çš„ goal å®šä¹‰ï¼ˆfuture[-1]ï¼‰")
    print("  3. âœ… è®­ç»ƒå¥åº·æ£€æŸ¥ï¼ˆæ¯ epoch éªŒè¯ ADE/FDEï¼‰")
    print("  4. âœ… å¼‚å¸¸è‡ªåŠ¨ä¸­æ­¢ï¼ˆå‰ 5 epoch ADE > 20kmï¼‰")
    print(f"\næ•°æ®ç›®å½•: {config['traj_dir']}")
    print(f"FASåˆ’åˆ†æ–‡ä»¶: {config['fas_split_file']}")
    print()
    
    # è®­ç»ƒä¸‰ä¸ªé˜¶æ®µ
    results = {}
    
    for phase in ['fas1', 'fas2', 'fas3']:
        try:
            result = train_terratnt_phase(phase, config)
            if result:
                results[phase] = result
        except Exception as e:
            print(f"âœ— {phase.upper()} è®­ç»ƒå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            results[phase] = {'status': 'failed', 'error': str(e)}
    
    # ä¿å­˜ç»“æœ
    results_file = Path(config['save_dir']) / 'terratnt_training_results_fixed.json'
    
    # è½¬æ¢ numpy ç±»å‹ä¸º Python åŸç”Ÿç±»å‹
    def convert_to_native(obj):
        if isinstance(obj, dict):
            return {k: convert_to_native(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [convert_to_native(v) for v in obj]
        elif isinstance(obj, (np.float32, np.float64)):
            return float(obj)
        elif isinstance(obj, (np.int32, np.int64)):
            return int(obj)
        return obj
    
    results_native = convert_to_native(results)
    
    with open(results_file, 'w') as f:
        json.dump(results_native, f, indent=2)
    
    print(f"\n{'='*60}")
    print("TerraTNT è®­ç»ƒç»“æœæ±‡æ€»ï¼ˆä¿®å¤ç‰ˆï¼‰")
    print('='*60)
    for phase, result in results.items():
        if 'best_val_ade' in result:
            print(f"âœ“ {phase.upper():10s} æœ€ä½³éªŒè¯ ADE: {result['best_val_ade']:.2f}m")
        else:
            print(f"âœ— {phase.upper():10s} å¤±è´¥: {result.get('error', 'Unknown')}")
    
    print(f"\nç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    # ä¸åŸºçº¿æ¨¡å‹å¯¹æ¯”
    print(f"\n{'='*60}")
    print("ä¸åŸºçº¿æ¨¡å‹å¯¹æ¯”ï¼ˆå‚è€ƒå€¼ï¼‰")
    print('='*60)
    print("  Trajectron++: ADE ~4,800m")
    print("  PECNet:       ADE ~7,800m")
    print("  Social-LSTM:  ADE ~9,900m")
    print("\nç›®æ ‡ï¼šTerraTNT åº”è¯¥æ¥è¿‘æˆ–ä¼˜äºè¿™äº›åŸºçº¿")


if __name__ == '__main__':
    main()
